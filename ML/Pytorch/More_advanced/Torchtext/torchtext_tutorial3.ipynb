{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torchtext_tutorial3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPvM8t8wuKUaHZhdRCZ7Eym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Syilun/Machine-Learning-Collections/blob/main/ML/Pytorch/More_advanced/Torchtext/torchtext_tutorial3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99kXpFXXftIX"
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8kcFRNlfxxU"
      },
      "source": [
        "### Load data from two text files where each row is a sentence ###\n",
        "english_txt = open(\"train_WMT_english.txt\", encoding=\"utf8\").read().split(\"\\n\")\n",
        "german_txt = open(\"train_WMT_german.txt\", encoding=\"utf8\").read().split(\"\\n\")\n",
        "\n",
        "raw_data = {\n",
        "    \"English\": [line for line in english_txt[0:1000]],\n",
        "    \"German\": [line for line in german_txt[0:1000]],\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(raw_data, columns=[\"English\", \"German\"])\n",
        "\n",
        "# create train and test set\n",
        "train, test = train_test_split(df, test_size=0.1)\n",
        "\n",
        "# Get train, test data to json and csv format which can be read by torchtext\n",
        "train.to_json(\"train.json\", orient=\"records\", lines=True)\n",
        "test.to_json(\"test.json\", orient=\"records\", lines=True)\n",
        "\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXVa7yAHmTdy",
        "outputId": "4068d489-e451-4a84-eb90-b766ebacdba6"
      },
      "source": [
        "### Now we're back to where we were in previous Tutorials ###\n",
        "\n",
        "\"\"\"\n",
        "To install spacy languages use:\n",
        "python -m spacy download en\n",
        "python -m spacy download de\n",
        "\"\"\"\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de\n",
        "\n",
        "spacy_eng = spacy.load('en')\n",
        "spacy_ger = spacy.load('de')\n",
        "\n",
        "\n",
        "def tokenize_eng(text):\n",
        "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "\n",
        "def tokenize_ger(text):\n",
        "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "\n",
        "english = Field(sequential=True, use_vocab=True, tokenize=tokenize_eng, lower=True)\n",
        "german = Field(sequential=True, use_vocab=True, tokenize=tokenize_ger, lower=True)\n",
        "\n",
        "fields = {\"English\": (\"eng\", english), \"German\": (\"ger\", german)}\n",
        "\n",
        "train_data, test_data = TabularDataset.splits(\n",
        "    path=\"\", train=\"train.json\", test=\"test.json\", format=\"json\", fields=fields\n",
        ")\n",
        "\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, test_data), batch_size=32, device=\"cuda\"\n",
        ")\n",
        "\n",
        "for batch in train_iterator:\n",
        "    print(batch)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2021.5.30)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-py3-none-any.whl size=14907055 sha256=8d423f880dda53ea2f7c33459a6a922d6ab22d316e35c814ba9a4d804edbb485\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kmc8o15j/wheels/00/66/69/cb6c921610087d2cab339062345098e30a5ceb665360e7b32a\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 69x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 100x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 49x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 57x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 80x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 69x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 47x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 57x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 48x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 98x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 56x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 83x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 47x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 58x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 48x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 60x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 4]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 49x4 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 29x4 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 53x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 86x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 59x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 56x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 51x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 64x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 79x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 63x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 52x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 57x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 58x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 73x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 47x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 66x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 56x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 67x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 72x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 81x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 47x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 48x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 36x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 71x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 55x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 77x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 56x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 75x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 84x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 59x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 64x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 59x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 50x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 70x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 45x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 70x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 63x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 62x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 50x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 96x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 166x32 (GPU 0)]\n",
            "\t[.ger]:[torch.cuda.LongTensor of size 61x32 (GPU 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egLESNVvn8Dl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}